{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Association Rule Mining\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Association Rule Mining:\n",
        "\n",
        "- Association rule mining (ARM) is a data analysis technique for uncovering relationships among variables in large datasets. Essentially, it operates on the principle of identifying frequent patterns, which are combinations of items that appear together in the dataset with regularity.\n",
        "\n",
        "- The method revolves around a key data mining algorithm known as the Frequent Pattern Mining (FPM) algorithm. FPM's core objective is to reveal correlations and associations between items that may not be immediately obvious. This technique surfaces patterns that indicate if the presence of one set of items is related to the presence of another set.\n",
        "\n",
        "- These patterns are typically expressed through association rules, a form of rule-based machine learning. Association rules are useful not only for uncovering anomalies and regularities within data but also for a variety of other applications. These applications range widely, from analysis in retail and marketing, such as basket analysis and cross-marketing strategies, to more technical realms like software bug tracking.\n",
        "\n",
        "- The discovery of frequent itemsets using algorithms like Apriori is integral to many data mining initiatives. These itemsets form the foundation for more complex analysis, such as sequence discovery, interesting pattern recognition, and, most notably, the mining of association rules.\n",
        "\n",
        "- A practical example of association rules in action is their use in understanding consumer behavior in retail settings. Such rules might reveal the frequency and conditions under which certain products are purchased together, offering valuable insights for marketing strategies and inventory management. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading in Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_data = pd.read_csv('../data/Final_Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       antecedents                     consequents  antecedent support  \\\n",
            "0              (M)                             (_)                0.04   \n",
            "1              (_)                             (M)                0.04   \n",
            "2              (M)                             (b)                0.04   \n",
            "3              (b)                             (M)                0.04   \n",
            "4              (M)                             (d)                0.04   \n",
            "...            ...                             ...                 ...   \n",
            "173469         (o)  (e, n, d, t, v, i, M, _, m, b)                0.04   \n",
            "173470         (M)  (e, n, d, t, v, i, o, _, m, b)                0.04   \n",
            "173471         (_)  (e, n, d, t, v, i, o, M, m, b)                0.04   \n",
            "173472         (m)  (e, n, d, t, v, i, o, M, _, b)                0.08   \n",
            "173473         (b)  (e, n, d, t, v, i, o, M, _, m)                0.04   \n",
            "\n",
            "        consequent support  support  confidence  lift  leverage  conviction  \\\n",
            "0                     0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "1                     0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "2                     0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "3                     0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "4                     0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "...                    ...      ...         ...   ...       ...         ...   \n",
            "173469                0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "173470                0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "173471                0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "173472                0.04     0.04         0.5  12.5    0.0368        1.92   \n",
            "173473                0.04     0.04         1.0  25.0    0.0384         inf   \n",
            "\n",
            "        zhangs_metric  \n",
            "0                 1.0  \n",
            "1                 1.0  \n",
            "2                 1.0  \n",
            "3                 1.0  \n",
            "4                 1.0  \n",
            "...               ...  \n",
            "173469            1.0  \n",
            "173470            1.0  \n",
            "173471            1.0  \n",
            "173472            1.0  \n",
            "173473            1.0  \n",
            "\n",
            "[173474 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "merged_data['Movement_binned'] = pd.cut(merged_data['Movement'], bins=[-float('inf'), 0, float('inf')], labels=['Down', 'Up'])\n",
        "\n",
        "merged_data['Sentiment'] = merged_data['TRAIN'].map({1: 'Positive', 0: 'Neutral', -1: 'Negative'})\n",
        "\n",
        "transactions = merged_data.groupby('Date')[['Movement_binned', 'Sentiment']].agg(lambda x: x.tolist())\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
        "\n",
        "print(rules)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As we can see, the dataset gathered from my project does not really suit ARM as it does not have categorical variables. Stock values and Text are not the target features which apriori expects. Therefore this technique does not work correctly."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
